The complexity of a \ac{LBA} increases with the complexity of the system it has
to work with.
Consider a load balancing algorithm that computes the target worker for a task,
where the size of the tasks are equal, the workers have the same capabilities
and the number of overall tasks is known.
Such an algorithm is not of complexity.
In fact, it can be implemented by a simple mathematical equation:
\begin{equation}
    i = j \% |W|
\end{equation}
Where $i$ is the number of the worker instance in set $W$ that will be assigned
with the task number $j$.
Though, such an environment is unlikely.

In todays systems, the size of a task cannot be predicted.
The capabilities of a worker instance may be known, but as tasks come in and are
assigned to workers, an algorithm has to implement some book-keeping to know
which worker has the least load at a given point in time.
This is not complex, though having only one load balancer in a large ecosystem
is highly unlikely, as it would be a single point of failure.
Instead, multiple load balancers are used.
Because of this, some synchronization method between the book-keeping of each
load balancer must be introduced to ensure the best distribution of tasks.

If worker instance $W_1$ has the least load at time $t_1$, the load balancer
$L_1$ might assign a number of tasks to it in $t_2$.
After that, $L_1$ must notify $L_2$ about the new load on $W_1$, which it does
in $t_3$.
In the meantime, load balancer $L_2$ might need to assign another set of tasks,
which it assignes to $W_1$ in $t_2$, because it does not know yet that $W_1$
isn't the least loaded worker anymore.
This causes $W_1$ to become overloaded in $t_3$.

\subsection{Random load balancing}

A cheap load balancing strategy is randomizing the target.
\begin{equation}
    i = rand() \% |W|
\end{equation}
Which has several advantages over other approaches:
\begin{itemize}
    \item Simplicity
    \item Few edge cases
    \item Easy failover
    \item Works distributed
\end{itemize} % TODO: cite http://www.codemesh.io/codemesh/tyler-mcmullen ?
Although, distributing load randomly does not guarantee the best distributing
over a given set of notes.
It is even possible that a small set of workers are assigned
with a huge number of tasks while other workers only handle a very small number
of tasks, resulting in a high load on some machines while others idle.

The desireable state is that each machine has the same workload, resulting in a
perfect distribution of load over all machines.
With an algorithm randomly assigning work to workers, the possibility exists
that the system ends up in an unbalanced state.
Though this is very unlikely, we can do better.

\subsection{\ac{JSQ}}

Another known load balancing algorithm is \ac{JSQ}.
With this algorithm, the load balancing mechanism implements some book-keeping
mechanism how many jobs are in the queues of the worker instances and selects
the instance with the shortest queue for a new task.
This algorithm can result in a ``herd effect'' in distributed environments,
where a subset of machines is either underutilized or overloaded with tasks.
That is likely, if the load balancing instance(s) has old information on the
utilization of the nodes as described in \cite{inpSLoadInfo}.

A surprisingly good optimization is the combination of the two algorithms
described above.
\begin{equation}
    \begin{aligned}
        x &= rand() \% |I| \\
        y &= rand() \% |I| \\
        i &= \begin{cases}
            x & \text{if } load(W_x) =< load(W_y)\\
            y & \text{if } load(W_x) > load(W_y)\\
        \end{cases}
    \end{aligned}
    \label{eq:randjsq}
\end{equation}
If we combine these algorithms, so we select two worker instances randomly and
now apply \ac{JSQ} on this new set of worker instances (see \ref{eq:randjsq}),
we get better distribution, as stated in \cite{powerOfTwoInRLB}.

\subsection{Hash based load balancing}

Another way of distributing load is using a hash algorithm to determine the
target server.
With this approach, each request gets hashed with a hash function.
The result of the hash function can be seen as number.
Taking this number modulo the number of servers yields the index of the target
server.
In his scenario, the number of servers has to be constant.
If a new server is added to the cluster, the modulo operation yields other
servers for the same requests as before, yielding cache effects useless
\cite{medVimeoEngin}.
Another implication of hash based load balancing is that consistent hashing is
less than ideal for load balancing, as requests are not distributed evenly over
content.
Consider a cluster for videos, where each server has a subset of the complete
data.
Naturally, cat videos are more likely to be requested by the user than other
videos, resulting in higher load on the servers holding this particular data.

\cite{medVimeoEngin} states that as RS-JSQ as proposed in \cite{powerOfTwoInRLB}
and \cite{powerOfTwoRandomChoices} was not suiteable for their problem, but
\ac{CHBL} as proposed by
\cite{ConsistentHashingWithBoundedLoads} was.
The guarantees of \ac{CHBL} are a upper bound of the load of each server
\cite{ConsistentHashingWithBoundedLoads},
distribution of requests is the same as with consistent hashing and some more
cache-friendly properties \cite{medVimeoEngin}.

The \ac{CHBL} algorithm was implemented and submitted to the HAProxy HTTP load
balancer open source project and on November 25, HAProxy 1.7.0 was published
with \ac{CHBL} available.
Real world measurements reveal a great benefit from applying \ac{CHBL}, as shown
in \cite{medVimeoEngin}.

% vim: set ts=4 sw=4 tw=0 noet :
