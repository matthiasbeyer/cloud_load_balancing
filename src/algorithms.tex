The complexity of a \ac{LBA} increases with the complexity of the system it has
to work with.
Consider a load balancing algorithm that computes the target worker for a task,
where the size of the tasks are equal, the workers have the same capabilities
and the number of overall tasks is known.
Such an algorithm is not of complexity.
In fact, it can be implemented by a simple mathematical equation:
\begin{equation}
    i = j \% |W|
\end{equation}
Where $i$ is the number of the worker instance in set $W$ that will be assigned
with the task number $j$.
Though, such an environment is unlikely.

In todays systems, the size of a task cannot be predicted.
The capabilities of a worker instance may be known, but as tasks come in and are
assigned to workers, an algorithm has to implement some book-keeping to know
which worker has the least load at a given point in time.
This is not complex, though having only one load balancer in a large ecosystem
is highly unlikely, as it would be a single point of failure.
Instead, multiple load balancers are used.
Because of this, some synchronization method between the book-keeping of each
load balancer must be introduced to ensure the best distribution of tasks.

If worker instance $W_1$ has the least load at time $t_1$, the load balancer
$L_1$ might assign a number of tasks to it in $t_2$.
After that, $L_1$ must notify $L_2$ about the new load on $W_1$, which it does
in $t_3$.
In the meantime, load balancer $L_2$ might need to assign another set of tasks,
which it assignes to $W_1$ in $t_2$, because it does not know yet that $W_1$
isn't the least loaded worker anymore.
This causes $W_1$ to become overloaded in $t_3$.

\subsection{Random load balancing}

A cheap load balancing strategy is randomizing the target.
\begin{equation}
    i = rand() \% |W|
\end{equation}
Which has several advantages over other approaches:
\begin{itemize}
    \item Simplicity
    \item Few edge cases
    \item Easy failover
    \item Works distributed
\end{itemize} % TODO: cite http://www.codemesh.io/codemesh/tyler-mcmullen ?
These properties are rather easy to replicate with non-random load balancing
algorithms, except the last one.

In a common load balancing environment, having only one load balancer
distributing tasks between worker instances is naive.
Commonly, at least one fail-over is deployed, sometimes several.
Also, in a large system, load balancers might be spread not only over server
racks but rather continents.
Making load balancers work with each other and synchronize state information
introduces high complexity.

Anyways, distributing load randomly does not guarantee the best distributing
over a given set of notes, neither with one load balancer nor with many.
It is even possible that a small set of workers are assigned
with a huge number of tasks while other workers only handle a very small number
of tasks, resulting in a high load on some machines while others idle.

The desireable state is that each machine has the same workload, resulting in a
perfect distribution of load over all machines.
With an algorithm randomly assigning work to workers, the possibility exists
that the system ends up in an unbalanced state.
Though this is very unlikely, we can do better.

\subsection{\ac{JSQ}}

A known load balancing algorithm is \ac{JSQ}.

With this algorithm, the load balancing mechanism implements some book-keeping
mechanism how many jobs are in the queues of the worker instances and selects
the instance with the shortest queue for a new task.

If this algorithm is applied in a non-distributed environment, it behaves
exactly like roundrobin \ref{chap:algo:rr}.
Applying it with several load-balancers, though, might yield some better
results, though synchronization must be implemented carefully.
As synchronization is rather expensive, one might implement a scheduled
synchronization which causes the instances to synchronize state information in a
periodic manner.
However, this can result in a ``herd effect'' in distributed environments,
where a subset of machines is either underutilized or overloaded with tasks.
This is caused by the old information of how the nodes are
utilized as described in.
Mechanisms exists to use this old information to estimate the current situation
and improve the decisions of the load balancing (\cite{inpSLoadInfo}).

As synchronization might be to complex and faulty to implement, querying the
servers for their queue length might be an alternative.
With a querying-mechanism, synchronization, and therefor blocking, would be
omitted.

However, querying a server instance for its queue length introduces complexity
to the servers and might also be a non-trivial task.

\subsection{\ac{RSJSQ}}

A surprisingly good optimization is the combination of the random load balancing
implementation with \ac{JSQ}.
\begin{equation}
    \begin{aligned}
        x &= rand() \% |I| \\
        y &= rand() \% |I| \\
        i &= \begin{cases}
            x & \text{if } load(W_x) =< load(W_y)\\
            y & \text{if } load(W_x) > load(W_y)\\
        \end{cases}
    \end{aligned}
    \label{eq:randjsq}
\end{equation}
Due to the fact that querying each server for its queue length
might be a non-trivial and expensive task,
selecting two servers randomly (or by a hash function applied to the task, as
stated in \cite{powerOfTwoRandomChoices}) and applying the \ac{JSQ} algorithm on
this subset of servers yields, obviousely, better performance as the number of
queries for the queue length is minimized.

As stated in \cite{powerOfTwoRandomChoices}, \ac{RSJSQ} might result in
$\Theta(log(log(n)))$ tasks on each server, rather than
$\Theta(log(n) / log(log(n)))$, where $n$ is the number of servers in the
environment.

\subsection{Hash based load balancing}

Another way of distributing load is using a hash algorithm to determine the
target server.
With this approach, each request gets hashed with a hash function.
The result of the hash function can be seen as number.
Taking this number modulo the number of servers yields the index of the target
server.
In his scenario, the number of servers has to be constant.
If a new server is added to the cluster, the modulo operation yields other
servers for the same requests as before, yielding cache effects useless
\cite{medVimeoEngin}.
Another implication of hash based load balancing is that consistent hashing is
less than ideal for load balancing, as requests are not distributed evenly over
content.
Consider a cluster for videos, where each server has a subset of the complete
data.
Naturally, cat videos are more likely to be requested by the user than other
videos, resulting in higher load on the servers holding this particular data.

In \cite{medVimeoEngin} is stated, that as \ac{RSJSQ} was not suiteable for
their problem.
Though, \ac{CHBL} as proposed by \cite{ConsistentHashingWithBoundedLoads} was.

\ac{CHBL} provides some guarantees which are fortunate for dynamic hash based
load balancing in distributed environments.
That is, mostly, an upper bound for the load of each server
\cite{ConsistentHashingWithBoundedLoads}
and some more cache-friendly properties \cite{medVimeoEngin}.
with \ac{CHBL}, distribution of requests is the same as with consistent hashing.

The \ac{CHBL} algorithm was implemented and submitted to the HAProxy HTTP load
balancer open source project and on November 25, HAProxy 1.7.0 was published
with \ac{CHBL} available.
Real world measurements reveal a great benefit from applying \ac{CHBL}, as shown
in \cite{medVimeoEngin}.

% vim: set ts=4 sw=4 tw=0 noet :
